{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark 逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 逻辑回归简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logistic`回归是一种预测二分类常用算法。`Logistic`回归是广义线性模型的一种特殊情况，可以预测标签的发射概率。\n",
    "\n",
    "以下示例显示了如何使用弹性网正则化，训练二项式和多项式逻辑回归模型进行二分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 逻辑回归示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取波士顿房价的数据\n",
    "data = datasets.load_breast_cancer().get('data')\n",
    "target = datasets.load_breast_cancer().get('target')\n",
    "feature_names = datasets.load_breast_cancer().get('feature_names')\n",
    "# 创建 Pyspark DataFrame\n",
    "df = pd.DataFrame(data, columns=feature_names)\n",
    "df['target'] = target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据导入 spark DataFrame\n",
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集合所有特征，放在features列里\n",
    "vec_assmebler = VectorAssembler(\n",
    "    inputCols=feature_names.tolist(),\n",
    "    outputCol='features')\n",
    "\n",
    "# 对 df 进行合并特征操作\n",
    "df_features = vec_assmebler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|[17.99,10.38,122....|     0|\n",
      "|[20.57,17.77,132....|     0|\n",
      "|[19.69,21.25,130....|     0|\n",
      "|[11.42,20.38,77.5...|     0|\n",
      "|[20.29,14.34,135....|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建包含输入特征 和 目标变量 target 的数据\n",
    "df_model = df_features.select('features', 'target')\n",
    "\n",
    "df_model.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 切分数据集（训练集、测试集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_model.randomSplit([0.7, 0.3], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T06:38:06.356128Z",
     "start_time": "2021-04-14T06:38:05.910854Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这里使用了两个正则化\n",
    "# 第一个防止过拟合\n",
    "# 第二个使特征稀疏（L1正则占比0.8）\n",
    "lr = LogisticRegression(labelCol='target', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# 拟合模型\n",
    "lrModel = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 模型超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|参数|描述|\n",
    "|----|----|\n",
    "|`regParam`|正则化项系数(默认`0.0`)，正则化项主要用于防止过拟合|\n",
    "|`elasticNetParam`|正则化范式比(默认0.0)，正则化一般有两种范式`L1(Lasso)`和`L2(Ridge)`。L1一般用于特征的稀疏化，L2一般用于防止过拟合。这里的参数即设置L1范式的占比，默认`0.0`即只使用`L2`范式|\n",
    "|`maxIter`|最大迭代次数，训练的截止条件，默认`100`次|\n",
    "|`family`|`binomial`(二分类)/`multinomial`(多分类)/`auto`，默认为auto。设为auto时，会根据数据中实际的标签情况设置是二分类还是多分类|\n",
    "|`tol`|训练的截止条件，两次迭代之间的改善小于`tol`训练将截止|\n",
    "|`fitIntercept`|是否拟合截距，默认为`True`|\n",
    "|`Standardization`|是否使用归一化，这里归一化只针对各维特征的方差进行|\n",
    "|`Thresholds/setThreshold`|设置多分类、二分类的判决阈值，多分类是一个数组，二分类是double值|\n",
    "|`AggregationDepth`|设置分布式统计时的层数，主要用在treeAggregate中，数据量越大，可适当加大这个值，默认为2|\n",
    "|`set*Col`|样本为DataFrame结构，这些是设置列名，方便训练时选取label，weight，feature等列|\n",
    "|`weightCol`||权重列名。如果不是集合或者为空，我们把所有实例的权重都当作1.0|\n",
    "\n",
    "|模型拟合后的模型参数|描述|\n",
    "|----|----|\n",
    "|`coefficientMatrix`|模型的系数矩阵|\n",
    "|`coefficients`|logistic回归的模型系数|\n",
    "|`evaluate(dataset)`|在测试集上评估模型|\n",
    "|`hasSummary`| 是否有summary|\n",
    "|`intercept`| 二变量logistic模型的截距|\n",
    "|`interceptVector`| 多变量logistic模型截距|\n",
    "|`summary`|获得summary|\n",
    "|`transform`|(dataset,param=None)|\n",
    "|`Summary`|拥有的属性|\n",
    "|`predictions`| 模型transform方法输出的预测数据|\n",
    "|`probabilityCol`| 给出每个类的概率|\n",
    "|`areaUnderROC`| 计算AUC|\n",
    "|`fMeasureByTreshold`| 返回带有两个字段(阈值，F-统计量)的数据框，beta=1.0|\n",
    "|`pr`| 返回精度-召回率两字段的数据框|\n",
    "|`precisionByTreshold`|返回带有阈值，精度两字段的数据框，应用了从转换后数据里的所有可能概率作为阈值来计算精度|\n",
    "|`recallByTreshold`| 返回带有阈值，召回率两字段的数据框，应用了从转换后数据里的所有可能概率作为阈值来计算召回率|\n",
    "|`roc`|返回带有两字段FPR, TPR的数据框|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 模型结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 截距与斜率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (30,[3,6,7,9,23,27],[-0.00014099545495094965,-0.6529983223676307,-2.769011341348917,6.61894935586978,-0.00011269667651682802,-1.5017692627526809])\n",
      "Intercept: 0.492392916154928\n"
     ]
    }
   ],
   "source": [
    "# 展示截距与斜率\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 训练批次的loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.6669299781827079\n",
      "0.6634547387535975\n",
      "0.6622459436817278\n",
      "0.6599143601680826\n",
      "0.6526705153820956\n",
      "0.651748886888337\n",
      "0.6515424190411283\n",
      "0.6511972766697709\n",
      "0.6508960644822539\n",
      "0.6503327571812717\n",
      "0.6500814182230683\n"
     ]
    }
   ],
   "source": [
    "# 模型迭代的历史记录，记录了每次迭代时的损失（loss）\n",
    "\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in lrModel.summary.objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 ROC与AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|FPR|                 TPR|\n",
      "+---+--------------------+\n",
      "|0.0|                 0.0|\n",
      "|0.0|0.012658227848101266|\n",
      "|0.0| 0.02531645569620253|\n",
      "|0.0|  0.0379746835443038|\n",
      "|0.0| 0.05063291139240506|\n",
      "|0.0| 0.06329113924050633|\n",
      "|0.0|  0.0759493670886076|\n",
      "|0.0| 0.08860759493670886|\n",
      "|0.0| 0.10126582278481013|\n",
      "|0.0| 0.11392405063291139|\n",
      "|0.0| 0.12658227848101267|\n",
      "|0.0| 0.13924050632911392|\n",
      "|0.0|  0.1518987341772152|\n",
      "|0.0| 0.16455696202531644|\n",
      "|0.0| 0.17721518987341772|\n",
      "|0.0|   0.189873417721519|\n",
      "|0.0| 0.20253164556962025|\n",
      "|0.0| 0.21518987341772153|\n",
      "|0.0| 0.22784810126582278|\n",
      "|0.0| 0.24050632911392406|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrModel.summary.roc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f\"areaUnderROC: {lrModel.summary.areaUnderROC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression_a133eb920df3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置模型的阈值达到最大 F score\n",
    "fMeasure = lrModel.summary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5, current: 0.5785299646147778)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.explainParam('threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多项回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 多项回归\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# 拟合模型\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# 展示斜率与截距\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "zh-cn",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "zh-cn",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
