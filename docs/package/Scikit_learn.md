> SelectFromModel

`sklearn`在`Feature selection`模块中内置了一个`SelectFromModel`，
该模型可以通过`Model`本身给出的指标对特征进行选择，
`SelectFromModel` 是一个通用转换器,
其需要的`Model`只需要带有`conef_`或者`feature_importances`属性,
那么就可以作为`SelectFromModel`的`Model`来使用. 
如果相关的`coef_`或者`featureimportances`属性值低于预先设置的阈值，
这些特征将会被认为不重要并且移除掉。除了指定数值上的阈值之外，
还可以通过给定字符串参数来使用内置的启发式方法找到一个合适的阈值。
可以使用的启发式方法有`mean`、`median`以及使用浮点数乘以这些（例如，0.1*mean ）。

根据基础学习的不同，在estimator中有两种选择方式

第一种：是基于`L1`的特征选择，使用`L1`正则化的线性模型会得到稀疏解，
当目标是降低维度的时候，可以使用`sklearn`中的给予`L1`正则化的线性模型，
比如`LinearSVC`，逻辑回归，或者`Lasso`。但是要注意的是：在 `SVM` 和逻辑回归中，
参数 `C` 是用来控制稀疏性的：小的 `C` 会导致少的特征被选择。使用 `Lasso`，`alpha` 的值越大，
越少的特征会被选择。

第二种：是给予`Tree`的特征选择，`Tree`类的算法包括决策树，随机森林等会在训练后，
得出不同特征的重要程度，我们也可以利用这一重要属性对特征进行选择。

但是无论选择哪一种学习器，我们都要记住的是我们的特征选择的最终标准应当是选择最好的特征，
而非必须依照某种方法进行选择。特征选取并不一定升，所有特征有效的情况下，
去除的特征只能带来模型性能的下降，
即使不是全部有效很多时候，
低重要程度的特征也并不一定代表着一定会导致模型性能的下降，
因为某种度量方式并不代表着该特征的最终效果，很多时候我们的度量方式，往往只是一个参考而已。

- [通过模型进行特征选择](https://blog.csdn.net/fontthrone/article/details/79064930)
