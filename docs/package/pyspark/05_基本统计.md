#! https://zhuanlan.zhihu.com/p/467885234

# PySpark 常用统计方法

![Image](https://pic4.zhimg.com/80/v2-5db1a82996ec388725185ae900a58008.jpg)

### stats

> 中位数

```python
wind = Window.partitionBy('name')
med = F.expr('percentile_approx(score, 0.5)')
df.groupBy('name').agg(med.alias('med_val')).show()
```

假如不仅要计算每个人的中位数，还想保留原始数据，可以用如下代码：

```python
df.withColumn('med_val', med.over(wind)).show()
```

> 计算不同比重的分位数，可以用如下代码：

```python
med = F.expr('percentile_approx(score, array(0.25, 0.5, 0.75))')
df.withColumn('med_val', med.over(wind)).show()
```


```python
#定义窗口信息：数据窗口根据ID进行分区，根据ID,DATA_DATE进行排序。
window = Window.orderBy("ID","DATA_DATE").partitionBy("ID")
#将列'R'进行平移，新增一列'R_1'。lead是第二行平移到第一行，lag是第一行平移到第二行，结合实际需求进行选择。
df = df.withColumn('R_1',lead(col('R')).over(window))
```

> Pyspark 分位数统计

```python
def quantile(col: str, percent=0.5):
    """
    描述：PySpark 对 DataFrame 进行分位数统计。

    参数：
    :param col: 需要统计的字段名称
    :param percent: 分位点
    :return : pyspark.sql.functions

    示例：
    >>> stats = [quantile('col', i).alias(f'{i}') for i in [0, 0.25, 0.5, 0.75, 1]]
    >>> df.agg(*stats).show()
    """
    return F.expr(f'percentile_approx({col}, {percent})')
```